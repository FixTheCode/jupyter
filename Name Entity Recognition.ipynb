{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1:** Extracting names mentioned in a tweet. We are using spaCy NLP library in this example. This is a highly performant NLP library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "# the installation will take a while when first run\n",
    "# verbose output is supresses using a juypter feature call cell magic\n",
    "# remove the first line and run again to see output\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# load a library so we can print coloured text\n",
    "!{sys.executable} -m pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Noun phrases\n",
      " ['I', 'favour', 'people', 'talent', 'this country', 'I', 'favour', 'control', 'Boris Johnson', 'UK immigration', 'a Tory government', 'immigration']\n",
      "\n",
      "Verbs\n",
      " ['come', 'describe', 'would', 'work', 'pledge', 'cut']\n",
      "\n",
      "People mentioned in tweet\n",
      "\n",
      "\u001b[34mBoris Johnson\u001b[0m\n",
      "\u001b[34mPriti Patel\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from termcolor import colored\n",
    "\n",
    "# load the English, tokenizer, tagger, parser and NER clever stuff\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# used a tweet as the sample text\n",
    "tweet = (\"I'm in favour of people of talent being able to come to this country... but I'm also \"\n",
    "         \"in favour of control Boris Johnson describes how UK immigration would work under a Tory government, \"\n",
    "         \"as Home Secretary Priti Patel pledges to cut immigration overall.\")\n",
    "doc = nlp(tweet)\n",
    "\n",
    "# analyze syntax\n",
    "print (\"\\nNoun phrases\\n\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print (\"\\nVerbs\\n\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# display just the names mentioned in the tweet\n",
    "print(\"\\nPeople mentioned in tweet\\n\")\n",
    "for entity in doc.ents:\n",
    "    if (entity.label_ == \"PERSON\"): \n",
    "        print (colored(entity.text, 'blue'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2:** Extracting multiple names from a block of text. The first example seems to work, but can multiple names be extracted reliably from unstructured text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Truman, Doris Day, Red China, Johnnie Ray\n",
      "South Pacific, Walter Winchell, Joe DiMaggio\n",
      "Joe McCarthy, Richard Nixon, Studebaker, television\n",
      "North Korea, South Korea, Marilyn Monroe\n",
      "Rosenbergs, H-bomb, Sugar Ray, Panmunjom\n",
      "Brando, \"The King and I\" and \"The Catcher in the Rye\"\n",
      "Eisenhower, vaccine, England's got a new queen\n",
      "Marciano, Liberace, Santayana goodbye\n",
      "We didn't start the fire\n",
      "It was always burning\n",
      "Since the world's been turning\n",
      "We didn't start the fire\n",
      "No we didn't light it\n",
      "But we tried to fight it\n",
      "Joseph Stalin, Malenkov, Nasser and Prokofiev\n",
      "Rockefeller, Campanella, Communist Bloc\n",
      "Roy Cohn, Juan Peron, Toscanini, Dacron\n",
      "Dien Bien Phu falls, \"Rock Around the Clock\"\n",
      "Einstein, James Dean, Brooklyn's got a winning team\n",
      "Davy Crockett, Peter Pan, Elvis Presley, Disneyland\n",
      "Bardot, Budapest, Alabama, Krushchev\n",
      "Princess Grace, \"Peyton Place\", trouble in the Suez\n",
      "We didn't start the fire\n",
      "It was always burning\n",
      "Since the world's been turning\n",
      "We didn't start the fire\n",
      "No we didn't light it\n",
      "But we tried to fight it\n",
      "Little Rock, Pasternak, Mickey Mantle, Kerouac\n",
      "Sputnik, Chou En-Lai, \"Bridge on the River Kwai\"\n",
      "Lebanon, Charlse de Gaulle, California baseball\n",
      "Starkweather, homicide, children of thalidomide\n",
      "Buddy Holly, \"Ben Hur\", space monkey, Mafia\n",
      "Hula hoops, Castro, Edsel is a no-go\n",
      "U2, Syngman Rhee, payola and Kennedy\n",
      "Chubby Checker, \"Psycho\", Belgians in the Congo\n",
      "We didn't start the fire\n",
      "It was always burning\n",
      "Since the world's been turning\n",
      "We didn't start the fire\n",
      "No we didn't light it\n",
      "But we tried to fight it\n",
      "Hemingway, Eichmann, \"Stranger in a Strange Land\"\n",
      "Dylan, Berlin, Bay of Pigs invasion\n",
      "\"Lawrence of Arabia\", British Beatlemania\n",
      "Ole Miss, John Glenn, Liston beats Patterson\n",
      "Pope Paul, Malcolm X, British politician sex\n",
      "JFK, blown away, what else do I have to say\n",
      "We didn't start the fire\n",
      "It was always burning\n",
      "Since the world's been turning\n",
      "We didn't start the fire\n",
      "No we didn't light it\n",
      "But we tried to fight it\n",
      "Birth control, Ho Chi Minh, Richard Nixon back again\n",
      "Moonshot, Woodstock, Watergate, punk rock\n",
      "Begin, Reagan, Palestine, terror on the airline\n",
      "Ayatollah's in Iran, Russians in Afghanistan\n",
      "\"Wheel of Fortune\", Sally Ride, heavy metal, suicide\n",
      "Foreign debts, homeless vets, AIDS, crack, Bernie Goetz\n",
      "Hypodermics on the shores, China's under martial law\n",
      "Rock and roller cola wars, I can't take it anymore\n",
      "We didn't start the fire\n",
      "It was always burning\n",
      "Since the world's been turning\n",
      "We didn't start the fire\n",
      "But when we are gone\n",
      "Will it still burn on, and on, and on, and on\n",
      "We didn't start the fire\n",
      "It was always burning\n",
      "Since the world's been turning\n",
      "We didn't start the fire\n",
      "No we didn't light it\n",
      "But we tried to fight it\n",
      "We didn't start the fire\n",
      "It was always burning\n",
      "Since the world's been turning\n",
      "We didn't start the fire\n",
      "No we didn't light it\n",
      "But we tried to fight it\n",
      "\n",
      "People Billy Joel mentions...\n",
      "\n",
      "1   \u001b[34m['Harry Truman']\u001b[0m PERSON\n",
      "2   \u001b[34m['Johnnie Ray']\u001b[0m PERSON\n",
      "3   \u001b[34m['Walter Winchell']\u001b[0m PERSON\n",
      "4   \u001b[34m['Joe DiMaggio']\u001b[0m PERSON\n",
      "5   \u001b[34m['Joe McCarthy']\u001b[0m PERSON\n",
      "6   \u001b[34m['Richard Nixon']\u001b[0m PERSON\n",
      "7   \u001b[34m['Marilyn Monroe']\u001b[0m PERSON\n",
      "8   \u001b[34m['Sugar Ray']\u001b[0m PERSON\n",
      "9   \u001b[34m['Eisenhower']\u001b[0m PERSON\n",
      "10   \u001b[34m['Joseph Stalin']\u001b[0m PERSON\n",
      "11   \u001b[34m['Malenkov']\u001b[0m PERSON\n",
      "12   \u001b[34m['Nasser']\u001b[0m PERSON\n",
      "13   \u001b[34m['Roy Cohn']\u001b[0m PERSON\n",
      "14   \u001b[34m['Juan Peron']\u001b[0m PERSON\n",
      "15   \u001b[34m['Toscanini']\u001b[0m PERSON\n",
      "16   \u001b[34m['Bien Phu']\u001b[0m PERSON\n",
      "17   \u001b[34m['Einstein']\u001b[0m PERSON\n",
      "18   \u001b[34m['James Dean']\u001b[0m PERSON\n",
      "19   \u001b[34m['Davy Crockett']\u001b[0m PERSON\n",
      "20   \u001b[34m['Peter Pan']\u001b[0m PERSON\n",
      "21   \u001b[34m['Elvis Presley']\u001b[0m PERSON\n",
      "22   \u001b[34m['Grace']\u001b[0m PERSON\n",
      "23   \u001b[34m['Mickey Mantle']\u001b[0m PERSON\n",
      "24   \u001b[34m['Chou En-Lai']\u001b[0m PERSON\n",
      "25   \u001b[34m['Ben Hur']\u001b[0m PERSON\n",
      "26   \u001b[34m['Castro']\u001b[0m PERSON\n",
      "27   \u001b[34m['Syngman Rhee']\u001b[0m PERSON\n",
      "28   \u001b[34m['Kennedy']\u001b[0m PERSON\n",
      "29   \u001b[34m['Chubby Checker']\u001b[0m PERSON\n",
      "30   \u001b[34m['Hemingway']\u001b[0m PERSON\n",
      "31   \u001b[34m['John Glenn']\u001b[0m PERSON\n",
      "32   \u001b[34m['Patterson']\u001b[0m PERSON\n",
      "33   \u001b[34m['Pope Paul']\u001b[0m PERSON\n",
      "34   \u001b[34m['Malcolm X']\u001b[0m PERSON\n",
      "35   \u001b[34m['JFK']\u001b[0m PERSON\n",
      "36   \u001b[34m['Ho Chi Minh']\u001b[0m PERSON\n",
      "37   \u001b[34m['Richard Nixon']\u001b[0m PERSON\n",
      "38   \u001b[34m['Reagan']\u001b[0m PERSON\n",
      "39   \u001b[34m['Sally Ride']\u001b[0m PERSON\n",
      "40   \u001b[34m['Bernie Goetz']\u001b[0m PERSON\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import sys\n",
    "import os\n",
    "from termcolor import colored\n",
    "\n",
    "# load the English, tokenizer, tagger, parser and NER clever stuff\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# load a suitable test file, the lyrics to We Didn't Start the Fire by Billy Joel\n",
    "f = open('Files/lyrics.txt', 'r')\n",
    "\n",
    "# show the lyrics for the Gen Z's looking at this\n",
    "lyrics = f.read()\n",
    "print(lyrics)\n",
    "\n",
    "# lets see how many names are identified\n",
    "doc = nlp(lyrics)\n",
    "print(\"\\nPeople Billy Joel mentions...\\n\")\n",
    "name_count=0\n",
    "for entity in doc.ents:\n",
    "    if (entity.label_ == \"PERSON\"):\n",
    "        name_count+=1\n",
    "        print (name_count, ' ',colored(entity.text.splitlines(), 'blue'), entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the above code is not bad but the trained Machine Learning model that is used has missed some names and incorrectly identifed others. Some of the errors come from the way two single names end one line and begin the next. This is assumed to be a name e.g. Kerouac Sputnik, Beatlemania Ole Miss and Psycho.\n",
    "\n",
    "Some names are missed completely such as Eisenhower and Davy Crockett. The take away here is that this sort of process is not for situations where 100% of names in a document must be extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3:** OCR. This example shows how to extract names from images. Both typed and handwritten examples are tested. Pytesseract is a wrapper to Google's Tesseract-OCR Engine which also needs to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "# install an OCR library\n",
    "import sys\n",
    "!conda install -y -c conda-forge tesseract\n",
    "!{sys.executable} -m pip install Pillow\n",
    "!{sys.executable} -m pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Pool Ladder\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Player Name Skill\n",
      "Player 1 | Robin Banks Advanced\n",
      "Player 2 Joe Bloggs Good\n",
      "Player 3 Frank Sidebottom | Ace\n",
      "Player 4 | Sally Snider Lucky\n",
      "Player 5 Mary Marks Advanced\n",
      "Player 6 Billy Kidson Good\n",
      "Player 7 Robin Robyns Average\n",
      "Player 8 Kim Jon Ho Average\n",
      "Player 9 Aimee Bisset Average\n",
      "Company Pool Ladder\n",
      "\n",
      " \n",
      "\n",
      "Player 6 Billy kidson Good\n",
      "\n",
      " \n",
      "\n",
      "â€˜Player 8 | ea Jen te overage\n"
     ]
    }
   ],
   "source": [
    "import pytesseract \n",
    "from pytesseract import image_to_string\n",
    "from PIL import Image\n",
    "\n",
    "def ocr(filename):\n",
    "    txt = pytesseract.image_to_string(Image.open(filename))\n",
    "    return txt\n",
    "\n",
    "txt = ocr('Files/image.png')\n",
    "print(txt)\n",
    "\n",
    "txt2 = ocr('Files/handwritten.png')\n",
    "print(txt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the OCR of the handwritten text is poor. To overcome this you would need to train a tesseract model or use a combination of other vision detection software and machine learning tools such as OpenCV and TensorFlow. The code for this becomes much more complex.\n",
    "\n",
    "**Example 4:** Extracting names from the OCR data. spaCy was pretty good so we'll give it a try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "People Billy Joel mentions...\n",
      "\n",
      "1   ['Joe Bloggs Good'] PERSON\n",
      "2   ['Frank'] PERSON\n",
      "3   ['| Sally'] PERSON\n",
      "4   ['Mary Marks'] PERSON\n",
      "5   ['Billy Kidson Good'] PERSON\n",
      "6   ['Robin Robyns'] PERSON\n",
      "7   ['Kim Jon Ho'] PERSON\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# load the English, tokenizer, tagger, parser and NER clever stuff\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# lets see how many names are identified\n",
    "doc = nlp(txt)\n",
    "print(\"\\nPeople Billy Joel mentions...\\n\")\n",
    "name_count=0\n",
    "for entity in doc.ents:\n",
    "    if (entity.label_ == \"PERSON\"):\n",
    "        name_count+=1\n",
    "        print (name_count, ' ',entity.text.splitlines(), entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do better than this with some pre processing.   When running locally using Docker vs Azure Notebooks there were slight differences in the accuracy of the detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Company Pool Ladder     Player Name SkillPlayer \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "  Robin Banks AdvancedPlayer 2 \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joe Bloggs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " GoodPlayer 3 \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Frank Sidebottom\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "  \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AcePlayer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " 4  \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sally\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " Snider LuckyPlayer 5 \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mary Marks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AdvancedPlayer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " 6 \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Billy Kidson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " GoodPlayer 7 \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Robin Robyns AveragePlayer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " 8 \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kim Jon Ho AveragePlayer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " 9 Aimee Bisset Average</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "s = sp(txt.strip().replace('\\n','').replace('|',''))\n",
    "\n",
    "displacy.render(s, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
